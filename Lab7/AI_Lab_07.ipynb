{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56gSHw87PZ8W"
   },
   "source": [
    "Problem Statement 1 and 2 :\n",
    "Randomly select 60 percent of labeled data (from each class) for constructing the tree (training).  Test for the rest of 40 percent data.  Find out the accuracy of the classification tree with the help of confusion matrix and F-score. Use the entropy measure for selection of attributes.\n",
    "Repeat the above exercise 20 times.  Calculate the average accuracy of classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_b-ImFHbFaXn",
    "outputId": "dcb0626e-b168-4edc-bc00-7edfacbe00a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     buying  maint  doors person lug_boot safety    cls\n",
      "0     vhigh  vhigh      2      2    small    low  unacc\n",
      "1     vhigh  vhigh      2      2    small    med  unacc\n",
      "2     vhigh  vhigh      2      2    small   high  unacc\n",
      "3     vhigh  vhigh      2      2      med    low  unacc\n",
      "4     vhigh  vhigh      2      2      med    med  unacc\n",
      "...     ...    ...    ...    ...      ...    ...    ...\n",
      "1723    low    low  5more   more      med    med   good\n",
      "1724    low    low  5more   more      med   high  vgood\n",
      "1725    low    low  5more   more      big    low  unacc\n",
      "1726    low    low  5more   more      big    med   good\n",
      "1727    low    low  5more   more      big   high  vgood\n",
      "\n",
      "[1728 rows x 7 columns]\n",
      "Average Confusion Matrix:\n",
      "[[142   2   7   1]\n",
      " [  2  23   0   1]\n",
      " [  6   0 477   0]\n",
      " [  1   1   0  23]]\n",
      "\n",
      "Average F1 Score: 0.9639742078829098\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the car dataset from CSV\n",
    "url = 'car.csv'  # Replace with the actual path or URL of your dataset\n",
    "car_data = pd.read_csv(url)\n",
    "print(car_data)\n",
    "# Convert categorical variables to numerical using one-hot encoding\n",
    "features = ['buying', 'maint', 'doors', 'person', 'lug_boot', 'safety']\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "y = car_data.cls\n",
    "X = pd.get_dummies(car_data[features])\n",
    "# # Number of repetitions\n",
    "num_repeats = 20\n",
    "\n",
    "# # Lists to store results\n",
    "f1_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    # Split the data into training (60%) and testing (40%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y)\n",
    "\n",
    "    # Create a Decision Tree classifier with entropy as the criterion\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the performance using confusion matrix and F1-score\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate and print the average F1-score and confusion matrix\n",
    "average_f1 = np.mean(f1_scores, axis=0)\n",
    "average_conf_matrix = np.mean(conf_matrices, axis=0)\n",
    "\n",
    "print(\"Average Confusion Matrix:\")\n",
    "print(average_conf_matrix.astype(int))\n",
    "print(\"\\nAverage F1 Score:\", average_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_pb-jQcPj51"
   },
   "source": [
    "Problem Statement 3 :\n",
    "Repeat steps 1 and 2 with Gini index as a measure for selection of attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCwsMGODPMJd",
    "outputId": "128b6bb3-9188-4ba7-b51f-ef5d89f1c9b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     buying  maint  doors person lug_boot safety    cls\n",
      "0     vhigh  vhigh      2      2    small    low  unacc\n",
      "1     vhigh  vhigh      2      2    small    med  unacc\n",
      "2     vhigh  vhigh      2      2    small   high  unacc\n",
      "3     vhigh  vhigh      2      2      med    low  unacc\n",
      "4     vhigh  vhigh      2      2      med    med  unacc\n",
      "...     ...    ...    ...    ...      ...    ...    ...\n",
      "1723    low    low  5more   more      med    med   good\n",
      "1724    low    low  5more   more      med   high  vgood\n",
      "1725    low    low  5more   more      big    low  unacc\n",
      "1726    low    low  5more   more      big    med   good\n",
      "1727    low    low  5more   more      big   high  vgood\n",
      "\n",
      "[1728 rows x 7 columns]\n",
      "Average Confusion Matrix:\n",
      "[[141   1   9   1]\n",
      " [  3  23   0   1]\n",
      " [  7   0 475   0]\n",
      " [  1   1   0  22]]\n",
      "\n",
      "Average F1 Score: 0.9595434604863483\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the car dataset from CSV\n",
    "url = 'car.csv'  # Replace with the actual path or URL of your dataset\n",
    "car_data = pd.read_csv(url)\n",
    "print(car_data)\n",
    "# Convert categorical variables to numerical using one-hot encoding\n",
    "features = ['buying', 'maint', 'doors', 'person', 'lug_boot', 'safety']\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "y = car_data.cls\n",
    "X = pd.get_dummies(car_data[features])\n",
    "# # Number of repetitions\n",
    "num_repeats = 20\n",
    "\n",
    "# # Lists to store results\n",
    "f1_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    # Split the data into training (60%) and testing (40%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y)\n",
    "\n",
    "    # Create a Decision Tree classifier with Gini index as the criterion\n",
    "    clf = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the performance using confusion matrix and F1-score\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate and print the average F1-score and confusion matrix\n",
    "average_f1 = np.mean(f1_scores, axis=0)\n",
    "average_conf_matrix = np.mean(conf_matrices, axis=0)\n",
    "\n",
    "print(\"Average Confusion Matrix:\")\n",
    "print(average_conf_matrix.astype(int))\n",
    "print(\"\\nAverage F1 Score:\", average_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSR8OjnfQZaW"
   },
   "source": [
    "Entropy Measure with 70% training dataset and 30% testing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFEdmnZcPXRd",
    "outputId": "07ea0e61-089f-4e09-e737-55d6763df15c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     buying  maint  doors person lug_boot safety    cls\n",
      "0     vhigh  vhigh      2      2    small    low  unacc\n",
      "1     vhigh  vhigh      2      2    small    med  unacc\n",
      "2     vhigh  vhigh      2      2    small   high  unacc\n",
      "3     vhigh  vhigh      2      2      med    low  unacc\n",
      "4     vhigh  vhigh      2      2      med    med  unacc\n",
      "...     ...    ...    ...    ...      ...    ...    ...\n",
      "1723    low    low  5more   more      med    med   good\n",
      "1724    low    low  5more   more      med   high  vgood\n",
      "1725    low    low  5more   more      big    low  unacc\n",
      "1726    low    low  5more   more      big    med   good\n",
      "1727    low    low  5more   more      big   high  vgood\n",
      "\n",
      "[1728 rows x 7 columns]\n",
      "Average Confusion Matrix:\n",
      "[[108   1   3   1]\n",
      " [  2  17   0   0]\n",
      " [  4   0 357   0]\n",
      " [  1   0   0  18]]\n",
      "\n",
      "Average F1 Score: 0.968405506332892\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the car dataset from CSV\n",
    "url = 'car.csv'  # Replace with the actual path or URL of your dataset\n",
    "car_data = pd.read_csv(url)\n",
    "print(car_data)\n",
    "# Convert categorical variables to numerical using one-hot encoding\n",
    "features = ['buying', 'maint', 'doors', 'person', 'lug_boot', 'safety']\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "y = car_data.cls\n",
    "X = pd.get_dummies(car_data[features])\n",
    "# # Number of repetitions\n",
    "num_repeats = 20\n",
    "\n",
    "# # Lists to store results\n",
    "f1_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    # Split the data into training (70%) and testing (30%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "    # Create a Decision Tree classifier with entropy as the criterion\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the performance using confusion matrix and F1-score\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate and print the average F1-score and confusion matrix\n",
    "average_f1 = np.mean(f1_scores, axis=0)\n",
    "average_conf_matrix = np.mean(conf_matrices, axis=0)\n",
    "\n",
    "print(\"Average Confusion Matrix:\")\n",
    "print(average_conf_matrix.astype(int))\n",
    "print(\"\\nAverage F1 Score:\", average_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPVoMC6oQm5m"
   },
   "source": [
    "Gini Index Measure with 70% training dataset and 30% testing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2OfdxQ9bQIov",
    "outputId": "67f7eb48-2123-4fcb-e2a3-2d78153ef1e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     buying  maint  doors person lug_boot safety    cls\n",
      "0     vhigh  vhigh      2      2    small    low  unacc\n",
      "1     vhigh  vhigh      2      2    small    med  unacc\n",
      "2     vhigh  vhigh      2      2    small   high  unacc\n",
      "3     vhigh  vhigh      2      2      med    low  unacc\n",
      "4     vhigh  vhigh      2      2      med    med  unacc\n",
      "...     ...    ...    ...    ...      ...    ...    ...\n",
      "1723    low    low  5more   more      med    med   good\n",
      "1724    low    low  5more   more      med   high  vgood\n",
      "1725    low    low  5more   more      big    low  unacc\n",
      "1726    low    low  5more   more      big    med   good\n",
      "1727    low    low  5more   more      big   high  vgood\n",
      "\n",
      "[1728 rows x 7 columns]\n",
      "Average Confusion Matrix:\n",
      "[[106   1   6   0]\n",
      " [  1  18   0   0]\n",
      " [  5   0 357   0]\n",
      " [  1   1   0  17]]\n",
      "\n",
      "Average F1 Score: 0.9627956592574257\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the car dataset from CSV\n",
    "url = 'car.csv'  # Replace with the actual path or URL of your dataset\n",
    "car_data = pd.read_csv(url)\n",
    "print(car_data)\n",
    "# Convert categorical variables to numerical using one-hot encoding\n",
    "features = ['buying', 'maint', 'doors', 'person', 'lug_boot', 'safety']\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "y = car_data.cls\n",
    "X = pd.get_dummies(car_data[features])\n",
    "# # Number of repetitions\n",
    "num_repeats = 20\n",
    "\n",
    "# # Lists to store results\n",
    "f1_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    # Split the data into training (70%) and testing (30%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "    # Create a Decision Tree classifier with Gini index as the criterion\n",
    "    clf = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the performance using confusion matrix and F1-score\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate and print the average F1-score and confusion matrix\n",
    "average_f1 = np.mean(f1_scores, axis=0)\n",
    "average_conf_matrix = np.mean(conf_matrices, axis=0)\n",
    "\n",
    "print(\"Average Confusion Matrix:\")\n",
    "print(average_conf_matrix.astype(int))\n",
    "print(\"\\nAverage F1 Score:\", average_f1)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
